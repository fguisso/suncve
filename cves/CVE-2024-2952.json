{"cveId": "CVE-2024-2952", "cwe": ["CWE-76", "CWE-76", "CWE-76"], "cvss": [{"baseScore": "9.8", "version": "3.0", "Attack Vector": "None", "Attack Complexity": "Low", "Privileges Required": "None", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "High", "Availability Impact": "High"}], "references": ["https://huntr.com/bounties/a9e0a164-6de0-43a4-a640-0cbfb54220a4", "https://github.com/berriai/litellm/commit/8a1cdc901708b07b7ff4eca20f9cb0f1f0e8d0b3"], "description": ["BerriAI/litellm is vulnerable to Server-Side Template Injection (SSTI) via the `/completions` endpoint. The vulnerability arises from the `hf_chat_template` method processing the `chat_template` parameter from the `tokenizer_config.json` file through the Jinja template engine without proper sanitization. Attackers can exploit this by crafting malicious `tokenizer_config.json` files that execute arbitrary code on the server."], "published": "2024-04-10T17:15:54.823", "state": "PUBLIC", "vendorName": ["berriai"], "productName": ["berriai/litellm"], "github": {"advisories": [], "commits": ["https://github.com/berriai/litellm/commit/8a1cdc901708b07b7ff4eca20f9cb0f1f0e8d0b3"], "pocAdvisorie": null, "repo": "https://github.com/berriai/litellm/", "info": {"exist": true, "topics": ["ai-gateway", "anthropic", "azure-openai", "bedrock", "gateway", "langchain", "llm", "llm-gateway", "llmops", "openai", "openai-proxy", "vertex-ai"], "langs": {"Python": 12379776, "TypeScript": 1043895, "HTML": 88022, "JavaScript": 25959, "Shell": 4998, "Dockerfile": 3238, "Ruby": 3229, "Smarty": 2462, "Bicep": 909, "Makefile": 896, "CSS": 790}, "avatar": "https://avatars.githubusercontent.com/u/121462774?v=4", "stargazers": 20276, "language": "Python"}}, "pocList": []}