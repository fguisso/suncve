{"cveId": "CVE-2024-5206", "cwe": ["CWE-921", "CWE-921", "CWE-922", "CWE-921", "CWE-922"], "cvss": [{"baseScore": "4.7", "version": "3.1", "Attack Vector": "Low", "Attack Complexity": "High", "Privileges Required": "Low", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "None", "Availability Impact": "None"}], "references": ["https://huntr.com/bounties/14bc0917-a85b-4106-a170-d09d5191517c", "https://github.com/scikit-learn/scikit-learn/commit/70ca21f106b603b611da73012c9ade7cd8e438b8"], "description": ["A sensitive data leakage vulnerability was identified in scikit-learn's TfidfVectorizer, specifically in versions up to and including 1.4.1.post1, which was fixed in version 1.5.0. The vulnerability arises from the unexpected storage of all tokens present in the training data within the `stop_words_` attribute, rather than only storing the subset of tokens required for the TF-IDF technique to function. This behavior leads to the potential leakage of sensitive information, as the `stop_words_` attribute could contain tokens that were meant to be discarded and not stored, such as passwords or keys. The impact of this vulnerability varies based on the nature of the data being processed by the vectorizer."], "published": "2024-06-06T19:16:06.363", "state": "PUBLIC", "vendorName": ["scikit-learn"], "productName": ["scikit-learn/scikit-learn"], "github": {"advisories": [], "commits": ["https://github.com/scikit-learn/scikit-learn/commit/70ca21f106b603b611da73012c9ade7cd8e438b8"], "pocAdvisorie": null, "repo": "https://github.com/scikit-learn/scikit-learn/", "info": {"exist": true, "topics": ["data-analysis", "data-science", "machine-learning", "python", "statistics"], "langs": {"Python": 12383868, "Cython": 728558, "C++": 147428, "Shell": 48275, "C": 41895, "Meson": 32388, "CSS": 11277, "Makefile": 1034}, "avatar": "https://avatars.githubusercontent.com/u/365630?v=4", "stargazers": 61653, "language": "Python"}}, "pocList": []}