{"cveId": "CVE-2023-29374", "cwe": ["CWE-74", "CWE-74", "CWE-74", "CWE-74"], "cvss": [{"baseScore": "9.8", "version": "3.1", "Attack Vector": "None", "Attack Complexity": "Low", "Privileges Required": "None", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "High", "Availability Impact": "High"}], "references": ["https://github.com/hwchase17/langchain/pull/1119", "https://github.com/hwchase17/langchain/issues/814", "https://twitter.com/rharang/status/1641899743608463365/photo/1", "https://github.com/hwchase17/langchain/issues/1026"], "description": ["In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method."], "published": "2023-04-05T02:15:37.340", "state": "PUBLIC", "vendorName": ["n/a"], "productName": ["n/a"], "github": {"advisories": [], "commits": [], "pocAdvisorie": null, "repo": null, "info": {}}, "pocList": []}