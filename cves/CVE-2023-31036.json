{"cveId": "CVE-2023-31036", "cwe": ["CWE-23", "CWE-23", "CWE-22", "CWE-23", "CWE-22"], "cvss": [{"baseScore": "7.5", "version": "3.1", "Attack Vector": "None", "Attack Complexity": "High", "Privileges Required": "Low", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "High", "Availability Impact": "High"}], "references": ["https://nvidia.custhelp.com/app/answers/detail/a_id/5509"], "description": ["NVIDIA Triton Inference Server for Linux and Windows contains a vulnerability where, when it is launched with the non-default command line option --model-control explicit, an attacker may use the model load API to cause a relative path traversal. A successful exploit of this vulnerability may lead to code execution, denial of service, escalation of privileges, information disclosure, and data tampering."], "published": "2024-01-12T17:15:09.183", "state": "PUBLIC", "vendorName": ["nvidia"], "productName": ["Triton Inference Server"], "github": {"advisories": [], "commits": [], "pocAdvisorie": null, "repo": null, "info": {}}, "pocList": []}