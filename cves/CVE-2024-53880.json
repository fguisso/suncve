{"cveId": "CVE-2024-53880", "cwe": ["CWE-190", "CWE-190", "CWE-190"], "cvss": [{"baseScore": "4.9", "version": "3.1", "Attack Vector": "None", "Attack Complexity": "Low", "Privileges Required": "High", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "None", "Integrity Impact": "None", "Availability Impact": "High"}], "references": ["https://nvidia.custhelp.com/app/answers/detail/a_id/5612"], "description": ["NVIDIA Triton Inference Server contains a vulnerability in the model loading API, where a user could cause an integer overflow or wraparound error by loading a model with an extra-large file size that overflows an internal variable. A successful exploit of this vulnerability might lead to denial of service."], "published": "2025-02-12T01:15:08.940", "state": "PUBLIC", "vendorName": ["NVIDIA"], "productName": ["Triton Inference Server"], "github": {"advisories": [], "commits": [], "pocAdvisorie": null, "repo": null, "info": {}}, "pocList": []}