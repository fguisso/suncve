{"cveId": "CVE-2025-29783", "cwe": ["CWE-502", "CWE-502", "CWE-502"], "cvss": [{"baseScore": "9.0", "version": "3.1", "Attack Vector": "Adjacent", "Attack Complexity": "Low", "Privileges Required": "Low", "User Interaction": "None", "Scope": "Complete", "Confidentiality Impact": "High", "Integrity Impact": "High", "Availability Impact": "High"}], "references": ["https://github.com/vllm-project/vllm/security/advisories/GHSA-x3m8-f7g5-qhm7", "https://github.com/vllm-project/vllm/pull/14228", "https://github.com/vllm-project/vllm/commit/288ca110f68d23909728627d3100e5a8db820aa2"], "description": ["vLLM is a high-throughput and memory-efficient inference and serving engine for LLMs. When vLLM is configured to use Mooncake, unsafe deserialization exposed directly over ZMQ/TCP on all network interfaces will allow attackers to execute remote code on distributed hosts. This is a remote code execution vulnerability impacting any deployments using Mooncake to distribute KV across distributed hosts. This vulnerability is fixed in 0.8.0."], "published": "2025-03-19T16:15:32.477", "state": "PUBLIC", "vendorName": ["vllm-project"], "productName": ["vllm"], "github": {"advisories": ["https://github.com/vllm-project/vllm/security/advisories/GHSA-x3m8-f7g5-qhm7"], "commits": ["https://github.com/vllm-project/vllm/commit/288ca110f68d23909728627d3100e5a8db820aa2"], "pocAdvisorie": {}, "repo": "https://github.com/vllm-project/vllm/", "info": {"exist": true, "topics": ["amd", "cuda", "deepseek", "gpt", "hpu", "inference", "inferentia", "llama", "llm", "llm-serving", "llmops", "mlops", "model-serving", "pytorch", "qwen", "rocm", "tpu", "trainium", "transformer", "xpu"], "langs": {"Python": 12802168, "Cuda": 1551348, "C++": 534031, "C": 92703, "Shell": 83241, "CMake": 52729, "Dockerfile": 14193}, "avatar": "https://avatars.githubusercontent.com/u/136984999?v=4", "stargazers": 43618, "language": "Python"}}, "pocList": []}