{"cveId": "CVE-2024-46946", "cwe": ["CWE-20", "CWE-20"], "cvss": [{"baseScore": "9.8", "version": "3.1", "Attack Vector": "None", "Attack Complexity": "Low", "Privileges Required": "None", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "High", "Availability Impact": "High"}], "references": ["https://cwe.mitre.org/data/definitions/95.html", "https://github.com/langchain-ai/langchain/releases/tag/langchain-experimental%3D%3D0.3.0", "https://docs.sympy.org/latest/modules/codegen.html", "https://gist.github.com/12end/68c0c58d2564ef4141bccd4651480820#file-cve-2024-46946-txt"], "description": ["langchain_experimental (aka LangChain Experimental) 0.1.17 through 0.3.0 for LangChain allows attackers to execute arbitrary code through sympy.sympify (which uses eval) in LLMSymbolicMathChain. LLMSymbolicMathChain was introduced in fcccde406dd9e9b05fc9babcbeb9ff527b0ec0c6 (2023-10-05)."], "published": "2024-09-19T05:15:11.857", "state": "PUBLIC", "vendorName": ["n/a"], "productName": ["n/a"], "github": {"advisories": [], "commits": [], "pocAdvisorie": null, "repo": null, "info": {}}, "pocList": []}