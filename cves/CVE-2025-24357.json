{"cveId": "CVE-2025-24357", "cwe": ["CWE-502", "CWE-502", "CWE-502"], "cvss": [{"baseScore": "7.5", "version": "3.1", "Attack Vector": "None", "Attack Complexity": "High", "Privileges Required": "None", "User Interaction": "Required", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "High", "Availability Impact": "High"}], "references": ["https://github.com/vllm-project/vllm/security/advisories/GHSA-rh4j-5rhw-hr54", "https://github.com/vllm-project/vllm/pull/12366", "https://github.com/vllm-project/vllm/commit/d3d6bb13fb62da3234addf6574922a4ec0513d04", "https://pytorch.org/docs/stable/generated/torch.load.html"], "description": ["vLLM is a library for LLM inference and serving. vllm/model_executor/weight_utils.py implements hf_model_weights_iterator to load the model checkpoint, which is downloaded from huggingface. It uses the torch.load function and the weights_only parameter defaults to False. When torch.load loads malicious pickle data, it will execute arbitrary code during unpickling. This vulnerability is fixed in v0.7.0."], "published": "2025-01-27T18:15:41.523", "state": "PUBLIC", "vendorName": ["vllm-project"], "productName": ["vllm"], "github": {"advisories": ["https://github.com/vllm-project/vllm/security/advisories/GHSA-rh4j-5rhw-hr54"], "commits": ["https://github.com/vllm-project/vllm/commit/d3d6bb13fb62da3234addf6574922a4ec0513d04"], "pocAdvisorie": {}, "repo": "https://github.com/vllm-project/vllm/", "info": {"exist": true, "topics": ["amd", "cuda", "deepseek", "gpt", "hpu", "inference", "inferentia", "llama", "llm", "llm-serving", "llmops", "mlops", "model-serving", "pytorch", "qwen", "rocm", "tpu", "trainium", "transformer", "xpu"], "langs": {"Python": 12802168, "Cuda": 1551348, "C++": 534031, "C": 92703, "Shell": 83241, "CMake": 52729, "Dockerfile": 14193}, "avatar": "https://avatars.githubusercontent.com/u/136984999?v=4", "stargazers": 43618, "language": "Python"}}, "pocList": []}